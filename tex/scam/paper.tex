\documentclass{article}
\usepackage{amsthm,amsmath,amsfonts,natbib,mathtools,custom_math}
\usepackage[hscale=0.7,vscale=0.8]{geometry}

\usepackage{subfigure}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{authblk}

\usepackage{yhmath}

\bibliographystyle{plainnat}

\title{Faithful Variable Screening for High-Dimensional Convex Regression}

%\author{
%Min Xu, Minhua Chen, John Lafferty
%}

\author[1]{Min Xu}
\author[2,3]{Minhua Chen}
\author[2,3]{John Lafferty}

\affil[1]{Machine Learning Department, Carnegie Mellon University}
\affil[2]{Department of Statistics, University of Chicago}
\affil[3]{Department of Computer Science, University of Chicago}


% ENVIRONMENTS
% \numberwithin{equation}{section}
% \theoremstyle{plain}
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{corollary}{Corollary}[section]
% \newtheorem{proposition}{Proposition}[section]
% \newtheorem{lemma}{Lemma}[section]
% \newtheoremstyle{remark}{\topsep}{\topsep}%
%      {\normalfont}% Body font
%      {}           % Indent amount (empty = no indent, \parindent = para indent)
%      {\bfseries}  % Thm head font
%      {.}          % Punctuation after thm head
%      {.5em}       % Space after thm head (\newline = linebreak)
%      {\thmname{#1}\thmnumber{ #2}\thmnote{ #3}}% Thm head spec
% \theoremstyle{remark}
% \newtheorem{remark}{Remark}[section]
% \newtheorem{example}{Example}[section]
% \newtheorem{assumption}{Assumption}[section]
% \newtheorem{definition}{Definition}[section]

\input{macros}

\begin{document}

% min's macros
\mathchardef\mh="2D

% John's macros
% \def\X{\mathcal{X}}
% \def\comma{\unskip,~}
% \def\truep{p^*}
% \def\div{\|\,}
% \long\def\comment#1{}
% \def\reals{{\mathbb R}}
% \def\P{{\mathbb P}}
% \def\E{{\mathbb E}}
% \def\Cov{\mathop{\text{Cov}}}
% \def\supp{\mathop{\text{supp}\kern.2ex}}
% \def\argmin{\mathop{\text{\rm arg\,min}}}
% \def\arginf{\mathop{\text{\rm arg\,inf}}}
% \def\argmax{\mathop{\text{\rm arg\,max}}}
% \let\tilde\widetilde
% \def\csd{${}^*$}
% \def\mld{${}^\dag$}
% \def\dos{${}^\ddag$}
% \def\W{\widetilde Y}
% \def\Z{\widetilde X}
% \let\hat\widehat
% \let\tilde\widetilde
% \def\given{{\,|\,}}
% \def\ds{\displaystyle}
% \def\bs{\backslash}
% \def\1{{(1)}}
% \def\2{{(2)}}
% \def\pn{{(n)}}
% \def\ip{{(i)}}
% \def\Xbar{\overline{X}}
% \def\except{\backslash}
% \def\npn{\mathop{\textit{NPN\,}}}
% \def\i{{(i)}}
% \def\cE{{\mathcal{C}}}
% \def\cM{{\mathcal{M}}}
% \def\cF{{\mathcal{F}}}
% \def\cP{{\mathcal{P}}}
% \def\cG{{\mathcal{G}}}
% \def\tr{\mathop{\text{tr}}}
% \long\def\comment#1{}
% \def\ti#1{#1}
% \def\titi#1{\textit{#1}}
% \def\cram{{\sc cram}}
% \def\spam{{\small\sc SpAM}}
% \def\diag{\mathop{\rm diag}}
% \def\ones{\mathbf{1}}
% \def\threebars{\mbox{$|\kern-.25ex|\kern-.25ex|$}}
% \def\fatnorm#1{\threebars #1 \threebars}
% \def\rank{\mathop{\rm rank}}
% \def\S{\mathcal{S}}
% \def\H{\mathcal{H}}
% \def\K{{K}}
% \def\rank{\mathop{\rm rank}}
% \def\half{{1/2}}
% \def\Y{\mathbb{Y}}
% \def\M{\mathbb{M}}
% \def\F{\mathbb{F}}
% \def\pinv{{-1}}
% %\def\ones{\mathds{1}}
% %\def\ones{1}
% \def\Res{Z}
% \def\Proj{P}
% \def\cN{{\mathcal N}}
% \def\cT{{\mathcal H}}
% \def\coloneqq{:=}
% \def\mathbf#1{\mbox{\boldmath $#1$}} 
% \def\bar#1{\overline{#1}}




\maketitle

\begin{abstract}
We consider the problem of estimating a convex function of several variables from noisy values of the function at a finite sample of input points. Convex function estimation is subject to the curse of dimensionality where the sample size necessary for consistent estimation increases exponentially with the dimensionality of the observed variables $p$. However, if the function is sparse, with $s << p$ relevant variables, then one could achieve consistency in the high-dimensional setting by first identifying the $s$ variables. We develop a faithful screening procedure to compute a set $S$ that contains the $s$ relevant variables. Our approach is a two-stage method that estimates a sum of $p$ one-dimensional convex functions, followed by one-dimensional concave regression fits on the residuals. The method is based on quadratic programming, and in contrast to standard sparse additive models, requires no tuning parameters for smoothness. Under appropriate assumptions, we prove that the procedure is faithful in the population setting, yielding no false negatives, and we give a finite sample statistical analysis. In addition, we introduce algorithms for efficiently carrying out the required quadratic programs. The approach leads to significant computational and statistical advantages over fitting a full model, and provides an effective, practical approach to variable screening in convex regression.

\end{abstract}
\vskip10pt

% \tableofcontents

\input{introduction}
\input{related_work}
\input{summary}
\input{additive_faithful}
\input{estimation}
\input{optimization}
\input{sparsistency}
\input{experiments}
\input{discussion}


\clearpage

%\bibliographystyle{plain}
\bibliography{local}

\newpage
\input{appendix}
%\newpage
%\input{notes}

\end{document}
