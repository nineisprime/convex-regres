\section{Additive Faithfulness}

The additive approximation incur error; a variable that is relevant in reality may be erroneously zeroed out as irrelevant under additive approximation. Such mistakes are inherent to the approximation and may persist even with infinite samples. Lemma~\ref{lem:general_int_reduction} below gives us some examples of errors made by the additive approximations that minimize the $L_2$ distance.

 \begin{lemma}
\label{lem:general_int_reduction}
Let $p$ be a probability distribution on $\mathbf{C}=[0,1]^s$ and let $X=(X_1,...,X_s) \sim p$. Let $f: \mathbf{C} \rightarrow \R$ be an integrable function and suppose WLOG that $\E f(X) = 0$.

Let $\ds f^*_1,...,f^*_s \coloneqq \arg\min \{ \E | f(X) - \sum_{k=1}^s f_k(X_k) |^2 \,:\, \forall k, \E f_k(X_k) = 0\}$. Then $f^*_k(x_k) = \E[ f(X) | x_k]$.
\end{lemma}

Lemma~\ref{lem:general_int_reduction} follows from the stationarity condition of the optimal solution. If $p$ is the uniform distribution, then $f^*_k(x_k) = \int_{\mathbf{x}_{-k}} f(x_k, \mathbf{x}_{-k}) d\mathbf{x}_{-k}$. 

\begin{example} We give two examples of additive errors under the uniform distribution.
\[
\trm{(Egg Carton)} \quad f(x_1, x_2) = \sin( 2\pi x_1) \sin( 2 \pi x_2) \qquad \trm{ for } (x_1, x_2) \in [0,1]^2
\]
For all $x_1$, $\int_{x_2} f(x_1, x_2) d x_2 = 0$ and also, for all $x_2$, $\int_{x_1} f(x_1, x_2) d x_1 = 0$. An additive approximation would set $f_1 = 0$ and $f_2 = 0$. 
\[
\trm{(Tilting Slope)} \quad f(x_1, x_2) = x_1 x_2 \qquad \trm{ for } x_1 \in [-1,1], x_2 \in [0,1]
\]
For all $x_2$, $\int_{x_1} f(x_1, x_2) d x_1 = 0$, therefore, we expect $f_2 = 0$ under the additive approximation. This function, for every fixed $x_2$, is a zero-intercept linear function of $x_1$ with slope exactly $x_2$.
\end{example}

\begin{figure}[htp]
%\subfigure[Egg Carton]{\includegraphics[scale=0.5]{figs/sine_wave_funct.eps}}
%\subfigure[Tilting Slope]{\includegraphics[scale=0.4]{figs/tilting_slope_funct.eps}}
\caption{Two examples of additively unfaithful functions. Relevant variables are zeroed out under an additive approximation because every ``slice'' of the function along those variables integrates to 0.}
\end{figure}

Remarkably, for many distributions, a convex multivariate function can always be faithfully approximated by an additive function. Let us formalize these notions first.

\begin{definition}
Let $\mathbf{C}=[0,1]^s$. $f:\mathbf{C}\rightarrow \R$. We say that $f$ \textbf{depends on} coordinate $k$ if there exist $x'_k \neq x_k$ such that $f(x'_k, \mathbf{x}_{-k})$ and $f(x_k, \mathbf{x}_{-k})$ are different functions of $\mathbf{x}_{-k}$. 

Let $p$ be a probability distribution on $\mathbf{C}$ and assume WLOG that $\E f(X) = 0$. Let $\ds f^*_1,...,f^*_s \coloneqq \arg\min \{ \E | f(X) - \sum_{k=1}^s f_k(X_k) |^2 \,:\, \forall k, \E f_k(X_k) = 0\}$. We say that $f$ is \textbf{additively faithful} under $p$ if $f^*_k = 0$ iff $f$ does not depend on coordinate $k$.
\end{definition}

\begin{theorem}
\label{thm:convex_faithful}
Let $p$ be a product distribution on $C=[0,1]^s$ so that $X_1,...,X_s$ are all independent. If $f$ is convex and twice differentiable, then $f$ is additively faithful under $p$.
\end{theorem}

We assumed twice differentiability in Theorem~\ref{thm:convex_faithful} to simplify the proof. We believe the smoothness condition is not necessary because every non-smooth convex function can be approximated arbitrarily well by a smooth one. 

From Lemma~\ref{lem:general_int_reduction}, we know intuitively that additive approximation zeroes out $k$ when, fixing $x_k$, every ``slice'' of $f$ integrates to zero. We prove Theorem~\ref{thm:convex_faithful} by showing that ``slices'' of convex functions which integrate to zero cannot be ``glued'' together while still maintaining convexity. We give the full proof in the appendix [TODO:where?]. 

Theorem~\ref{thm:convex_faithful} plays an important role in our sparsistency analysis, in which we prove that the additive approximation is sparsistency \emph{even when} the true function is not additive. 


