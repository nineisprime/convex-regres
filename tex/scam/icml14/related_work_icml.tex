\section{Related Work}

\cite{Raskutti:12,Kolch:10,dalalyan:12,bertin:08,devore:11}



%* Laetitia Comminges, Arnak S. Dalalyan 
%Tight conditions for consistency of variable selection 
%In the context of high dimensionality. 
%Ann. Statist, 40(5), 2667-2696, 2012 
%
%Comment: They estimate the coefficient of the regression function with respect to a Fourier basis and then threshold the estimated coefficients. They prove that sparsistency is achievable so long as $n > log p$ and $n > exp(s)$. They assume that the functions are smooth with respect to the Fourier basis. The fourier coefficients however seem difficult to estimate; it appears that the knowledge of the true density is required. They also provide lower bounds showing that sparsistency is un-achievable if $n < log p$ or if $n < exp(s)$.
%
%
%* Bertin, K. and Lecu´e, G. (2008). Selection of variables 
%and dimension reduction in high-dimensional non-parametric 
%regression. Electron. J. Stat. 2 1224–1241 
%
%Comment: They assume Holder smoothness and use multiple L1 regularized local polynomial smoothing to detect the sparsity pattern. They require that $p < log n$.
%
%
%* "Approximation of Functions of Few Variables in High Dimensions" 
%by DeVore, Petrova and Wojtaszczyk. 
%
%Comment: They show that variable selection under a scaling of $n > log
%p, n > exp(s)$ is possible if one adaptively selects the points on
%which the high-dimensional functions are evaluated.
%
